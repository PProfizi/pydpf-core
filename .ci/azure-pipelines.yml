# azure pipelines build and test pydpf

variables:
  ALLOW_PLOTTING: true
  package_name: ansys-dpf-core
  SHELLOPTS: 'errexit:pipefail'

trigger:
  branches:
    include:
    - '*'
    exclude:
    - gh-pages
  tags:
    include:
    - '*'

pr:
  branches:
    include:
    - '*'
    exclude:
    - '*no-ci*'

jobs:
- job: Windows
  variables:
    python.version: '3.8'
    ANSYS_VERSION: 221
    DISPLAY: ':99.0'
    PYANSYS_OFF_SCREEN: True
    DPF_PORT: 32772
    vstsPackageVersion: '22.1.0'
  pool:
    vmImage: 'windows-2019'

  steps:  
    - template: templates\prepare-environment-windows.yml
        
    - task: PublishBuildArtifacts@1
      displayName: 'WHEEL: publish artifacts'
      inputs:
        PathtoPublish: '$(System.DefaultWorkingDirectory)\dist'
        ArtifactName: 'ansys_dpf_core_wheel'
      enabled: true

    - template: templates\run-unit-tests-windows.yml

    - script: |
        cd $(System.DefaultWorkingDirectory)
        pytest --doctest-modules --junitxml=junit/test-doctests-results.xml ansys\dpf\core
      condition: always()
      displayName: Test API Docstrings
      timeoutInMinutes: 5

    - task: PublishTestResults@2
      inputs:
        testResultsFormat: 'JUnit'
        testResultsFiles: 'junit/test-doctests-results.xml'
        testRunTitle: 'docTestsTests'
        publishRunAttachments: true
      condition: always()

    - script:  |
        python .ci/run_examples.py
      displayName: 'Run example scripts'
      timeoutInMinutes: 5

    - script: |
        pip install twine
        python setup.py sdist
        twine upload --skip-existing dist/*
      displayName: 'Upload to PyPi'
      condition: contains(variables['Build.SourceBranch'], 'refs/tags/')
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: $(PYPI_TOKEN)
        TWINE_REPOSITORY_URL: "https://upload.pypi.org/legacy/"      
     

    - script: |
        type $(System.DefaultWorkingDirectory)\server\v$(ANSYS_VERSION)\aisol\bin\winx64\log.txt
      displayName:  'Show DPF Server Logs'
      condition: always() 
    
    - template: templates\kill-servers-windows.yml   


- job: WindowsAnsys2021R2
  variables:
    python.version: '3.8'
    ANSYS_VERSION: 212
    DISPLAY: ':99.0'
    PYANSYS_OFF_SCREEN: True
    DPF_PORT: 32772
    vstsPackageVersion: '21.2.3'
  condition: "false"
  pool:
    vmImage: 'windows-2019'

  steps:
    - template: templates\prepare-environment-windows.yml

    - script: |
            pip install ansys-grpc-dpf==0.3.0
      displayName: Install proper version of ansys-grpc-dpf

    - script: |
        rmdir /s /q .\ansys\
      displayName: Remote local copy of ansys-dpf-core

    - template: templates\run-unit-tests-windows.yml


- job: Linux
  condition: "false"
  variables:
    python.version: '3.7'  # due to VTK 8.1.2 requirement for docbuild
    ANSYS_VERSION: 221
    DISPLAY: ':99.0'
    PYANSYS_OFF_SCREEN: True
    DPF_PORT: 50055
    TEMP: $(System.DefaultWorkingDirectory)/temp
    AWP_ROOT221: $(System.DefaultWorkingDirectory)/server/v221
    vstsPackageVersion: "22.1.1"
    
  pool:
    vmImage: 'ubuntu-20.04'
  steps:
    - template: templates\prepare-environment-linux.yml

    - template: templates\run-unit-tests-linux.yml

    - script : |
        echo $0
        if pgrep -x "Ans.Dpf.Grpc" > /dev/null
        then
            pkill -f Ans.Dpf.Grpc.exe
        fi
      displayName: 'Kill all servers'
      condition: always()
      continueOnError: true

- job: DocumentationLinux
  condition: "false"
  variables:
    python.version: '3.7'  # due to VTK 8.1.2 requirement for docbuild
    ANSYS_VERSION: 221
    PYANSYS_OFF_SCREEN: True
    DPF_PORT: 50055
    TEMP: $(System.DefaultWorkingDirectory)/temp
    AWP_ROOT221: $(System.DefaultWorkingDirectory)/server/v$(ANSYS_VERSION)
    GH_DOC_BRANCH: 'gh-pages'
    vstsPackageVersion: "22.1.1"
    
  pool:
    vmImage: 'ubuntu-20.04'
  steps:
    - template: templates\prepare-environment-linux.yml

    - script: |
        pip install -r requirements_docs.txt
      displayName: Install documentation packages for Python

    - script: |
        sphinx-apidoc -o docs/source/api ansys ansys/dpf/core/aeneid.py -f --implicit-namespaces --separate --no-headings
        xvfb-run make -C docs html SPHINXOPTS="-w build_errors.txt -N"
      displayName: Build Documentation

    - task: ArchiveFiles@2
      inputs:
        rootFolderOrFile: '$(System.DefaultWorkingDirectory)/docs/build' 
        includeRootFolder: false 
        archiveType: 'zip'
        archiveFile: '$(System.DefaultWorkingDirectory)/docs/archive/doc-ansys-dpf-core.zip'
        replaceExistingArchive: true 
      displayName: 'DOCUMENTATION: zip artifacts'
      condition: always()
    
    - task: PublishBuildArtifacts@1
      displayName: 'DOCUMENTATION: publish artifacts'
      inputs:
        PathtoPublish: '$(System.DefaultWorkingDirectory)/docs/archive'
        ArtifactName: doc-ansys-dpf-core
      enabled: true
      condition: always()

    - powershell: |
        git init
        git checkout -b $(GH_DOC_BRANCH)
        git config --global user.name "pyansys-ci-bot"
        git config --global user.email "$(GH_EMAIL)"
        New-Item -ItemType file .nojekyll
        git add .
        git commit -m "Documentation generated by $(Build.DefinitionName)"
      displayName: "Init git and add docs"
      workingDirectory: docs/build/html

    - script: |
        git remote add origin https://$(GH_PAT)@github.com/pyansys/DPF-Core-docs
        git push -u origin $(GH_DOC_BRANCH) --force
      displayName: "Publish GitHub Pages merge commit"
      workingDirectory: docs/build/html
      condition: contains(variables['Build.SourceBranch'], 'refs/tags/')

    - script : |
        echo $0
        if pgrep -x "Ans.Dpf.Grpc" > /dev/null
        then
            pkill -f Ans.Dpf.Grpc.exe
        fi
      displayName: 'Kill all servers'
      condition: always()
      continueOnError: true
